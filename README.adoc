= Conative Gating
:toc: left
:toclevels: 3
:icons: font
:source-highlighter: rouge

SLM-as-Cerebellum for LLM Policy Enforcement

== Overview

Conative Gating implements a dual-layer policy enforcement system for AI-assisted coding:

1. **Policy Oracle** (deterministic): Fast rule-checking for forbidden languages, toolchain violations, and security patterns
2. **SLM Evaluator** (neural): Spirit-of-policy evaluation for edge cases (future implementation)

The system acts as a "cerebellum" - receiving proposals from an LLM, blocking obvious violations immediately, and using an SLM for nuanced evaluation of edge cases.

== Architecture

[source]
----
                    ┌─────────────────┐
                    │   LLM Proposal  │
                    └────────┬────────┘
                             │
                    ┌────────▼────────┐
                    │  Policy Oracle  │ ◄── Deterministic rules
                    │   (this crate)  │
                    └────────┬────────┘
                             │
              ┌──────────────┼──────────────┐
              │              │              │
        ┌─────▼─────┐  ┌─────▼─────┐  ┌─────▼─────┐
        │  BLOCKED  │  │   PASS    │  │  ESCALATE │
        │           │  │           │  │  to SLM   │
        └───────────┘  └───────────┘  └─────┬─────┘
                                            │
                                   ┌────────▼────────┐
                                   │  SLM Consensus  │
                                   │ (PBFT + weight) │
                                   └─────────────────┘
----

== Quick Start

=== Building

[source,bash]
----
cargo build --release
----

=== Running

[source,bash]
----
# Scan a directory for policy violations
./target/release/conative scan /path/to/project

# Check a single file
./target/release/conative check --file src/main.rs

# Check content directly
./target/release/conative check --content "const x: string = 'hello'"

# Show the default RSR policy
./target/release/conative policy

# Show policy as JSON
./target/release/conative policy --format json

# Validate a proposal JSON file
./target/release/conative validate proposal.json
----

== Policy Configuration

The default policy implements RSR (Reasonable Stack Requirements):

=== Language Tiers

[cols="1,3,2"]
|===
|Tier |Languages |Status

|**Tier 1** (Preferred)
|Rust, Elixir, Zig, Ada, Haskell, ReScript
|✓ Fully compliant

|**Tier 2** (Acceptable)
|Nickel, Racket
|⚠ Generates concern

|**Forbidden**
|TypeScript, Python, Go, Java
|✗ Hard violation
|===

=== Exceptions

Some languages are permitted in specific paths:

[source]
----
Python allowed in:
  - salt/    (Salt configuration)
  - training/ (ML training scripts)
----

=== Toolchain Rules

[cols="1,2,2"]
|===
|Tool |Requires |Reason

|npm
|deno
|Node.js must use Deno runtime
|===

=== Forbidden Patterns

* Hardcoded secrets (passwords, API keys in source code)

== Proposal Format

When validating proposals programmatically, use this JSON format:

[source,json]
----
{
  "id": "550e8400-e29b-41d4-a716-446655440000",
  "action_type": {"CreateFile": {"path": "src/util.rs"}},
  "content": "pub fn helper() -> String { ... }",
  "files_affected": ["src/util.rs"],
  "llm_confidence": 0.95
}
----

=== Action Types

* `CreateFile { path }` - Creating a new file
* `ModifyFile { path }` - Modifying existing file
* `DeleteFile { path }` - Deleting a file
* `ExecuteCommand { command }` - Running a command

== API Usage

[source,rust]
----
use policy_oracle::{Oracle, Proposal, ActionType};
use uuid::Uuid;

let oracle = Oracle::with_rsr_defaults();

let proposal = Proposal {
    id: Uuid::new_v4(),
    action_type: ActionType::CreateFile {
        path: "src/helper.rs".to_string()
    },
    content: "pub fn helper() { }".to_string(),
    files_affected: vec!["src/helper.rs".to_string()],
    llm_confidence: 0.9,
};

match oracle.check_proposal(&proposal) {
    Ok(result) => {
        match result.verdict {
            PolicyVerdict::Compliant => println!("OK"),
            PolicyVerdict::HardViolation(v) => println!("BLOCKED: {:?}", v),
            PolicyVerdict::SoftConcern(c) => println!("CONCERN: {:?}", c),
        }
    }
    Err(e) => eprintln!("Error: {}", e),
}
----

== Directory Scanning

[source,rust]
----
use policy_oracle::Oracle;
use std::path::Path;

let oracle = Oracle::with_rsr_defaults();
let result = oracle.scan_directory(Path::new("./my-project"))?;

println!("Files scanned: {}", result.files_scanned);
println!("Violations: {}", result.violations.len());
println!("Concerns: {}", result.concerns.len());
----

== Future: SLM Evaluation

The v2 release will include SLM-based "spirit violation" detection:

* Integration with llama.cpp for local inference
* PBFT consensus with 3-5 SLM nodes
* Asymmetric weighting (1.5x for inhibition signals)
* Training data from rhodibot categories

== License

AGPL-3.0-or-later

== Author

Jonathan D.A. Jewell <jonathan@hyperpolymath.org>
